Ética y Responsabilidad:
sesgos en los datos de IA, privacidad y discriminación en sistemas. 

La ética aplicada a la IA busca principalmente establecer principios y valores que guíen su desarrollo y aplicación con el objetivo de prevenir daños, así como promover y asegurar que la tecnología beneficie a todas las personas.

Los sesgos en los datos de IA se refieren a la discriminación sistemática que resulta de datos de entrenamiento incompletos, erróneos o que reflejan prejuicios humanos, lo que puede llevar a resultados de la IA que refuerzan o amplifican estereotipos y desigualdades.

 La discriminación en sistemas de IA se manifiesta cuando los algoritmos perpetúan o amplifican sesgos sociales, lo que lleva a resultados injustos para ciertos grupos. Esto ocurre principalmente por el uso de datos de entrenamiento incompletos o sesgados, y puede resultar en discriminación por raza, género, edad, orientación sexual, etc. Por ejemplo, un modelo de reconocimiento facial entrenado mayormente con personas de piel clara puede tener dificultades para identificar con precisión a personas con tonos de piel más oscuros. 

La privacidad de la IA es la práctica de proteger la información personal o sensible recopilada, utilizada, compartida o almacenada por la IA. La privacidad de la IA está estrechamente relacionada con la protección de los datos. 